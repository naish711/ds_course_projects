{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Cardio-Vascular paitent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Project - Phase 2 (MATH 2319)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors : Manikanta Naishadu Devabhakthuni ,\n",
    "          Varsha Shankar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to predict whether an individual is a cardiovascular paitent using the data provided from a kaggler. The dataset used in this study is from Kaggle [2]. This report is organised as follows the work done in Phase-1 of the project.\n",
    "This dataset has one target feature named as cardio , has two classes as '1' if the person is cardio and '0' if the person is not a cardio vascular paitent. The descriptive features include 5 numerical and 6 nominal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the below mentioned three binary classifiers to predicit the target feature.\n",
    "\n",
    "1. K-Nearest Neighbors\n",
    "\n",
    "2. Naive Bayes Classifier\n",
    "\n",
    "3. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started data transformation with the preprocessed data (data cleaning) from phase 1. This transformation approach includes label encoding for all features with more than two levels. Essentially we scaled the data to get all descriptive features into a single range of numerical value more likely between 0 to 1 to facilitate the feature selection.\n",
    "\n",
    "Then, we move on to feature selection ,in which we have used most popular Random Forrest Importance (RFI) with estimator of 100 trees with 10 maximum limited features.\n",
    "\n",
    "We have data instances more than 68k which more for the task. Hence we have chosen 30k instances for this study. We sampled the data randomly and split the data with stratification method in order to ensure the target sample is selected with equally distributed(ratio) class lablels .\n",
    "\n",
    "As process of hyperparameter tuning ,with the help of pipeline technique , we stack the RFI features to grid serach function in order to estimate the best parameters for all three classifiers. This helps to select an optimal model for each of the three classifier and to avoid overfitting of the each model.\n",
    "\n",
    "In the process of model selection , we considered 10 fold cross validation and paired t-test to check with statistical significance between three classifiers and chosen the best classifier according to the highest recall values which is genereated by classification report of each of the three classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chossing the working directory\n",
    "os.chdir('D:\\Machine learning\\ML Course Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier in the report, we have just imported the dataset that has been preprocessed in the phase 1. To recap, during data preprocessing we found some missing values, impossibles values and obvious typos in different features. We have successfully manipulated these values and dropped few columns (approx. 8 rows) which are obvious error and a column named as \"ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pre processed data from Phase-I of course project\n",
    "\n",
    "cardio = pd.read_csv(\"PreData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>95.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>71.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>68.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  \\\n",
       "0   50       1     168    62.0    110     80            1     1      0     0   \n",
       "1   55       0     156    85.0    140     90            3     1      0     0   \n",
       "2   52       0     165    64.0    130     70            3     1      0     0   \n",
       "3   48       1     169    82.0    150    100            1     1      0     0   \n",
       "4   48       0     156    56.0    100     70            1     1      0     0   \n",
       "5   60       0     151    67.0    120     80            2     2      0     0   \n",
       "6   61       0     157    93.0    130     80            3     1      0     0   \n",
       "7   62       1     178    95.0    130     90            3     3      0     0   \n",
       "8   48       0     158    71.0    110     70            1     1      0     0   \n",
       "9   54       0     164    68.0    110     70            1     1      0     0   \n",
       "\n",
       "   active  cardio  \n",
       "0       1       0  \n",
       "1       1       1  \n",
       "2       0       1  \n",
       "3       1       1  \n",
       "4       0       0  \n",
       "5       0       0  \n",
       "6       1       0  \n",
       "7       1       1  \n",
       "8       1       0  \n",
       "9       0       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset has 11 descriptive features and cardio as the target varaible\n",
    "cardio.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68992, 12)\n"
     ]
    }
   ],
   "source": [
    "print(cardio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo',\n",
       "       'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of statistics is shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "      <td>68992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.324849</td>\n",
       "      <td>0.348678</td>\n",
       "      <td>164.359317</td>\n",
       "      <td>74.119079</td>\n",
       "      <td>126.241405</td>\n",
       "      <td>81.620550</td>\n",
       "      <td>1.364376</td>\n",
       "      <td>1.225852</td>\n",
       "      <td>0.087851</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>0.803267</td>\n",
       "      <td>0.494898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.768156</td>\n",
       "      <td>0.476555</td>\n",
       "      <td>8.203868</td>\n",
       "      <td>14.327062</td>\n",
       "      <td>15.677191</td>\n",
       "      <td>8.214059</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.571797</td>\n",
       "      <td>0.283080</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.397532</td>\n",
       "      <td>0.499978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        gender        height        weight         ap_hi  \\\n",
       "count  68992.000000  68992.000000  68992.000000  68992.000000  68992.000000   \n",
       "mean      53.324849      0.348678    164.359317     74.119079    126.241405   \n",
       "std        6.768156      0.476555      8.203868     14.327062     15.677191   \n",
       "min       30.000000      0.000000     55.000000     21.000000     90.000000   \n",
       "25%       48.000000      0.000000    159.000000     65.000000    120.000000   \n",
       "50%       54.000000      0.000000    165.000000     72.000000    120.000000   \n",
       "75%       58.000000      1.000000    170.000000     82.000000    140.000000   \n",
       "max       65.000000      1.000000    250.000000    200.000000    170.000000   \n",
       "\n",
       "              ap_lo   cholesterol          gluc         smoke          alco  \\\n",
       "count  68992.000000  68992.000000  68992.000000  68992.000000  68992.000000   \n",
       "mean      81.620550      1.364376      1.225852      0.087851      0.053586   \n",
       "std        8.214059      0.678672      0.571797      0.283080      0.225200   \n",
       "min       65.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%       80.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "50%       80.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "75%       90.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "max      105.000000      3.000000      3.000000      1.000000      1.000000   \n",
       "\n",
       "             active        cardio  \n",
       "count  68992.000000  68992.000000  \n",
       "mean       0.803267      0.494898  \n",
       "std        0.397532      0.499978  \n",
       "min        0.000000      0.000000  \n",
       "25%        1.000000      0.000000  \n",
       "50%        1.000000      0.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68992 entries, 0 to 68991\n",
      "Data columns (total 12 columns):\n",
      "age            68992 non-null int64\n",
      "gender         68992 non-null int64\n",
      "height         68992 non-null int64\n",
      "weight         68992 non-null float64\n",
      "ap_hi          68992 non-null int64\n",
      "ap_lo          68992 non-null int64\n",
      "cholesterol    68992 non-null int64\n",
      "gluc           68992 non-null int64\n",
      "smoke          68992 non-null int64\n",
      "alco           68992 non-null int64\n",
      "active         68992 non-null int64\n",
      "cardio         68992 non-null int64\n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.3 MB\n"
     ]
    }
   ],
   "source": [
    "cardio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As nominal features like 'cholesterol','gluc' which has more than two level are in numerical format. In order to create encode them , we first them converted into categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio['cholesterol'] = cardio['cholesterol'].astype(object)\n",
    "cardio['gluc'] = cardio['gluc'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the target variable apart from the features and named as 'target' and the rest descriptive features are named as 'features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "features = cardio.drop(columns='cardio')\n",
    "target = cardio['cardio']\n",
    "target.value_counts()\n",
    "target = preprocessing.LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cholesterol', 'gluc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = cardio.columns[cardio.dtypes==object].tolist()\n",
    "\n",
    "features_cols "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of get_dummies function from pandas library in order to get the dummy variables for categorical varaibles having more than two levels. Particulaly in this dataset , most of the categorical variables having two level '1' and '0' which is more like TRUE or FALSE expect two features 'cholesterol' and 'gluc'. <br> As in the data description from source website, it is mentioned that 1,2,3 constitutes the degree of the substance present in the body/person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one-hot-encoding for categorical features with >2 levels\n",
    "features = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53732</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>76.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15127</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>79.0</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41950</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>91.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19715</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  \\\n",
       "53732   64       0     172    76.0    130     80      0     0       1   \n",
       "15127   49       1     182    79.0    140    100      1     0       1   \n",
       "41950   48       1     181    91.0    120     80      1     0       1   \n",
       "19715   48       0     161    70.0    120     80      0     0       1   \n",
       "14991   58       0     158    60.0    120     80      0     0       1   \n",
       "\n",
       "       cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  gluc_3  \n",
       "53732              0              0              1       1       0       0  \n",
       "15127              0              0              1       1       0       0  \n",
       "41950              0              1              0       1       0       0  \n",
       "19715              1              0              0       1       0       0  \n",
       "14991              1              0              0       1       0       0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(5, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform algorithms like KNN , Descion Tree etc., Scaling is the most important step in data preprocessing. Especially will performing the feature selection , all descriptive features must be on one scale i.e, in same range. <br> In this study, the least numerical value from all features is 0 and highest is 252(ap_hi) . Hence, we decided to perform scaling in order to proceed further for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "features_copy = features.copy()\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53732</th>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.307263</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15127</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651282</td>\n",
       "      <td>0.324022</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41950</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19715</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543590</td>\n",
       "      <td>0.273743</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528205</td>\n",
       "      <td>0.217877</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  gender    height    weight  ap_hi  ap_lo  smoke  alco  \\\n",
       "53732  0.971429     0.0  0.600000  0.307263  0.500  0.375    0.0   0.0   \n",
       "15127  0.542857     1.0  0.651282  0.324022  0.625  0.875    1.0   0.0   \n",
       "41950  0.514286     1.0  0.646154  0.391061  0.375  0.375    1.0   0.0   \n",
       "19715  0.514286     0.0  0.543590  0.273743  0.375  0.375    0.0   0.0   \n",
       "14991  0.800000     0.0  0.528205  0.217877  0.375  0.375    0.0   0.0   \n",
       "\n",
       "       active  cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  \\\n",
       "53732     1.0            0.0            0.0            1.0     1.0     0.0   \n",
       "15127     1.0            0.0            0.0            1.0     1.0     0.0   \n",
       "41950     1.0            0.0            1.0            0.0     1.0     0.0   \n",
       "19715     1.0            1.0            0.0            0.0     1.0     0.0   \n",
       "14991     1.0            1.0            0.0            0.0     1.0     0.0   \n",
       "\n",
       "       gluc_3  \n",
       "53732     0.0  \n",
       "15127     0.0  \n",
       "41950     0.0  \n",
       "19715     0.0  \n",
       "14991     0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features, columns=features_copy.columns).sample(5, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, we have use Random Forrest Algorithm to get the feature importance. At a glance, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble model for feature selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_features = 10\n",
    "model_rfi = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfi.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_rfi = features_copy.columns[fs_indices_rfi].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['weight', 'height', 'ap_hi', 'age', 'ap_lo', 'cholesterol_1',\n",
       "       'cholesterol_3', 'gender', 'active', 'smoke'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 15)\n",
      "(30000, 1)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 30000\n",
    "\n",
    "features_sample = pd.DataFrame(features).sample(n=n_samples, random_state=9).values\n",
    "target_sample = pd.DataFrame(target).sample(n=n_samples, random_state=9).values\n",
    "\n",
    "print(features_sample.shape)\n",
    "print(target_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 15)\n",
      "(12000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(features_sample, target_sample, \n",
    "                                                    test_size = 0.4, random_state=999,\n",
    "                                                    stratify = target_sample)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "cv_method = StratifiedKFold(n_splits=5, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# custom function for RFI feature selection inside a pipeline\n",
    "# here we use n_estimators=100\n",
    "class RFIFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # class constructor \n",
    "    # make sure class attributes end with a \"_\"\n",
    "    # per scikit-learn convention to avoid errors\n",
    "    def __init__(self, n_features_=10):\n",
    "        self.n_features_ = n_features_\n",
    "        self.fs_indices_ = None\n",
    "\n",
    "    # override the fit function\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from numpy import argsort\n",
    "        model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "        model_rfi.fit(X, y)\n",
    "        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n",
    "        return self \n",
    "    \n",
    "    # override the transform function\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.fs_indices_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_KNN = Pipeline(steps=[('rfi_fs', RFIFeatureSelector()), \n",
    "                           ('knn', KNeighborsClassifier())])\n",
    "\n",
    "params_pipe_KNN = {'rfi_fs__n_features_': [10, 20, features.shape[1]],\n",
    "                   'knn__n_neighbors': [1, 10, 20, 40, 60, 100],\n",
    "                   'knn__p': [1, 2, 5]}\n",
    "\n",
    "gs_pipe_KNN = GridSearchCV(estimator=pipe_KNN, \n",
    "                           param_grid=params_pipe_KNN, \n",
    "                           cv=cv_method,\n",
    "                           refit=True,\n",
    "                           n_jobs=-2,\n",
    "                           scoring='roc_auc',\n",
    "                           verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-2)]: Done 270 out of 270 | elapsed:  5.1min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "gs_pipe_KNN.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 60, 'knn__p': 1, 'rfi_fs__n_features_': 10}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_KNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7841814821750296"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_KNN.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Naive Baye's classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "X_train_transformed = PowerTransformer().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe_NB = Pipeline([('rfi_fs', RFIFeatureSelector()), \n",
    "                     ('nb', GaussianNB())])\n",
    "\n",
    "params_pipe_NB = {'rfi_fs__n_features_': [10, 20, features.shape[1]],\n",
    "                  'nb__var_smoothing': np.logspace(1,-3, num=200)}\n",
    "\n",
    "n_iter_search = 20\n",
    "gs_pipe_NB = RandomizedSearchCV(estimator=pipe_NB, \n",
    "                          param_distributions=params_pipe_NB, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          n_iter=n_iter_search,\n",
    "                          verbose=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   15.6s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gs_pipe_NB.fit(X_train_transformed, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfi_fs__n_features_': 10, 'nb__var_smoothing': 6.593188271333546}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7770914742255031"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_NB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_DT = Pipeline([('rfi_fs', RFIFeatureSelector()),\n",
    "                    ('dt', DecisionTreeClassifier(criterion='gini'))])\n",
    "\n",
    "params_pipe_DT = {'rfi_fs__n_features_': [10],\n",
    "                  'dt__max_depth': [3, 4, 5,6,7,8,9,10],\n",
    "                  'dt__min_samples_split': [2, 5]}\n",
    "\n",
    "gs_pipe_DT = GridSearchCV(estimator=pipe_DT, \n",
    "                          param_grid=params_pipe_DT, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:   12.9s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "gs_pipe_DT.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best parmeters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 6, 'dt__min_samples_split': 2, 'rfi_fs__n_features_': 10}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814834180463645"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_DT.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_method_ttest = StratifiedKFold(n_splits=10, random_state=999)\n",
    "\n",
    "cv_results_KNN = cross_val_score(estimator=gs_pipe_KNN.best_estimator_,\n",
    "                                 X=X_test,\n",
    "                                 y=y_test, \n",
    "                                 cv=cv_method_ttest, \n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923123891692838"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_KNN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = PowerTransformer().fit_transform(X_test)\n",
    "\n",
    "cv_results_NB = cross_val_score(estimator=gs_pipe_NB.best_estimator_,\n",
    "                                X=X_test_transformed,\n",
    "                                y=y_test, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789046075861584"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_NB.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_DT = cross_val_score(estimator=gs_pipe_DT.best_estimator_,\n",
    "                                X=X_test,\n",
    "                                y=y_test, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7917491402840351"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_DT.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistics and p-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=1.948739990342999, pvalue=0.08313476401277939)\n",
      "Ttest_relResult(statistic=-0.2466478599013119, pvalue=0.8107145437359558)\n",
      "Ttest_relResult(statistic=1.0539745273359413, pvalue=0.3193667587118561)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.ttest_rel(cv_results_KNN, cv_results_NB))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_KNN))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_KNN = gs_pipe_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_transformed = PowerTransformer().fit_transform(X_test)\n",
    "pred_NB = gs_pipe_NB.predict(Data_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_DT = gs_pipe_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report for K-Nearest Neighbor\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      6048\n",
      "           1       0.76      0.69      0.72      5952\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     12000\n",
      "   macro avg       0.74      0.73      0.73     12000\n",
      "weighted avg       0.74      0.73      0.73     12000\n",
      "\n",
      "\n",
      "Classification report for Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75      6048\n",
      "           1       0.81      0.52      0.63      5952\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     12000\n",
      "   macro avg       0.73      0.70      0.69     12000\n",
      "weighted avg       0.73      0.70      0.69     12000\n",
      "\n",
      "\n",
      "Classification report for Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      6048\n",
      "           1       0.76      0.68      0.72      5952\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     12000\n",
      "   macro avg       0.74      0.73      0.73     12000\n",
      "weighted avg       0.74      0.73      0.73     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\nClassification report for K-Nearest Neighbor\") \n",
    "print(metrics.classification_report(y_test, pred_KNN))\n",
    "print(\"\\nClassification report for Naive Bayes\") \n",
    "print(metrics.classification_report(y_test, pred_NB))\n",
    "print(\"\\nClassification report for Decision Tree\") \n",
    "print(metrics.classification_report(y_test, pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for K-Nearest Neighbor\n",
      "[[4720 1328]\n",
      " [1858 4094]]\n",
      "\n",
      "Confusion matrix for Naive Bayes\n",
      "[[5315  733]\n",
      " [2878 3074]]\n",
      "\n",
      "Confusion matrix for Decision Tree\n",
      "[[4754 1294]\n",
      " [1912 4040]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\nConfusion matrix for K-Nearest Neighbor\") \n",
    "print(metrics.confusion_matrix(y_test, pred_KNN))\n",
    "print(\"\\nConfusion matrix for Naive Bayes\") \n",
    "print(metrics.confusion_matrix(y_test, pred_NB))\n",
    "print(\"\\nConfusion matrix for Decision Tree\") \n",
    "print(metrics.confusion_matrix(y_test, pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On contradict to paired t-test results, classification report supports decision tree with high value of recall score compared to other two classifer. As true predicition of cardio vascular paitent can be identified sligtly higher by decision tree classifier to predict the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our modeling strategy has a two major limitations. First, since we have performed randomly selected raw predictive performance over interpretability.\n",
    "\n",
    "Second, we have chosen only a small subset of the full dataset considering the shorter run times as priority at this instant, both for training and testing. Since data is availble ie., more than half of the data is available, we could perform experiments with the entire data with apt consideration of spliting data set and validtion techniques.\n",
    "\n",
    "In future, we will continue our work to investigate the hidden patterns of the data,best approach to select important features and techniques to optimize the classifers in terms of parameters and data sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-near Neighbours model with 100 n_neighbours and 10 of the best features selected by Random Forest Importance (RFI) produces the highest cross-validated AUC score on the training data. In addition, when evaluated on the test set, the KNN model again outperforms both Naive Bayes and Decision tree models with respect to AUC scores. However, the Decision Tree model gives higher recall score on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cardiovascular Disease dataset-https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
